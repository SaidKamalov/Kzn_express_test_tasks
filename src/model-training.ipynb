{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model choosing and evaluation:\n",
    "\n",
    "This notebook contains tunning of support vector classifier [1] and evaluation results of a model with tunned hyper-parameters.\n",
    "However, several classifiers were tried: Knn-classifier with cosine similarity, and logistic regression with use of ovr. But all of these classiffiers did not succseed. \n",
    "\n",
    "One can agree that the reason of failures is the feature space. Encoding large text data leads to extremely sparce and high-dimensional feature space that is not good for classic ml classifiers. PCA was tried to reduce the dimension of the feature space, but to cover at least 95% of variance number of principal components is close to the initial dimensionality.\n",
    "\n",
    "So to conclude, further investigations are required to increase the quality of results. More advance techniques, such as anensemble learning, stacking, word-embedding for text-to-feature converting and neural networks are required. \n",
    "\n",
    "[1] To be precise, Linear SVC was used, it is similar to SVC with linear kernel. However, it is more efficient to use with large datasets due to its implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "TARGET_PATH = os.path.join(\"..\", \"data\", \"target.pkl\")\n",
    "TRAIN_ENC_PATH = os.path.join(\"..\", \"data\", \"train_encoded.npy\")\n",
    "TEST_ENC_PATH = os.path.join(\"..\", \"data\", \"test_encoded.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = pd.read_pickle(TARGET_PATH)\n",
    "X = np.load(TRAIN_ENC_PATH, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91116, 1500)\n",
      "(91116,)\n"
     ]
    }
   ],
   "source": [
    "# we can see that we have 1500 features\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\" Splitting train dataset to train and test parts \n",
    "    to be able to evaluate our model.\n",
    "    Also we keep the ratio of categories in the test part.\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/said/anaconda3/envs/env_jpt_notebooks/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............................C=1;, score=0.803 total time= 2.0min\n",
      "[CV 2/5] END ...............................C=1;, score=0.803 total time= 2.0min\n",
      "[CV 1/5] END ...............................C=1;, score=0.805 total time= 2.1min\n",
      "[CV 5/5] END ...............................C=1;, score=0.800 total time= 2.0min\n",
      "[CV 4/5] END ...............................C=1;, score=0.807 total time= 2.1min\n",
      "[CV 1/5] END ...............................C=5;, score=0.799 total time= 2.7min\n",
      "[CV 2/5] END ...............................C=5;, score=0.795 total time= 2.6min\n",
      "[CV 3/5] END ...............................C=5;, score=0.794 total time= 2.7min\n",
      "[CV 4/5] END ...............................C=5;, score=0.797 total time= 2.6min\n",
      "[CV 5/5] END ...............................C=5;, score=0.792 total time= 2.6min\n",
      "[CV 1/5] END ..............................C=10;, score=0.792 total time= 3.1min\n",
      "[CV 2/5] END ..............................C=10;, score=0.787 total time= 3.1min\n",
      "[CV 3/5] END ..............................C=10;, score=0.788 total time= 3.0min\n",
      "[CV 4/5] END ..............................C=10;, score=0.792 total time= 3.0min\n",
      "[CV 5/5] END ..............................C=10;, score=0.786 total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/said/anaconda3/envs/env_jpt_notebooks/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..............................C=15;, score=0.788 total time= 3.2min\n",
      "[CV 2/5] END ..............................C=15;, score=0.784 total time= 3.3min\n",
      "[CV 3/5] END ..............................C=15;, score=0.783 total time= 3.3min\n",
      "[CV 4/5] END ..............................C=15;, score=0.788 total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/said/anaconda3/envs/env_jpt_notebooks/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..............................C=15;, score=0.783 total time= 2.7min\n",
      "{'C': 1}\n",
      "0.8034910503750783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\" Hyper parameter tunning with Greed Search.\n",
    "    Regularization parametr is estimated.\n",
    "\"\"\"\n",
    "\n",
    "params = {\"C\": [1, 5, 10, 15]}\n",
    "\n",
    "greed_search = GridSearchCV(\n",
    "    param_grid=params,\n",
    "    estimator=LinearSVC(random_state=123),\n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=3,\n",
    "    verbose=3,\n",
    ")\n",
    "greed_search.fit(x_train, y_train)\n",
    "print(greed_search.best_params_)\n",
    "print(greed_search.best_score_)\n",
    "\n",
    "# the result is Linear SVC with c=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(C=1.0, random_state=123)\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120005633299404"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# getting f1-weighted score\n",
    "\n",
    "y_pred = svc.predict(x_test)\n",
    "f1_score(y_test,y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicton for test dataset\n",
    "\n",
    "test = np.load(TEST_ENC_PATH, allow_pickle=True)\n",
    "y_results = svc.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997646</td>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>927375</td>\n",
       "      <td>14922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1921513</td>\n",
       "      <td>2803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1668662</td>\n",
       "      <td>12044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467778</td>\n",
       "      <td>11581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16855</th>\n",
       "      <td>1914264</td>\n",
       "      <td>11645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16856</th>\n",
       "      <td>1310569</td>\n",
       "      <td>12357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16857</th>\n",
       "      <td>978095</td>\n",
       "      <td>13651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16858</th>\n",
       "      <td>797547</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>703835</td>\n",
       "      <td>11757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  predicted_category_id\n",
       "0         1997646                   2755\n",
       "1          927375                  14922\n",
       "2         1921513                   2803\n",
       "3         1668662                  12044\n",
       "4         1467778                  11581\n",
       "...           ...                    ...\n",
       "16855     1914264                  11645\n",
       "16856     1310569                  12357\n",
       "16857      978095                  13651\n",
       "16858      797547                   2740\n",
       "16859      703835                  11757\n",
       "\n",
       "[16860 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_EXT_PATH = os.path.join(\"..\", \"data\", \"test_extended.pkl\")\n",
    "\n",
    "product_id = np.array(pd.read_pickle(TEST_EXT_PATH)[\"product_id\"])\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"product_id\": product_id,\n",
    "        \"predicted_category_id\": y_results,\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = os.path.join('..','result.parquet')\n",
    "pd.DataFrame.to_parquet(result, RESULT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get confidence interval for f1_weighted statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8140703661434605,\n",
       " 0.8119780226132173,\n",
       " 0.8114968099936071,\n",
       " 0.8106872169197372,\n",
       " 0.8109119286564962,\n",
       " 0.8121224450274257,\n",
       " 0.8086702183534009,\n",
       " 0.8079159398005651,\n",
       " 0.8089228527740515,\n",
       " 0.8148371516363826,\n",
       " 0.8093051160424399,\n",
       " 0.8123384096903608,\n",
       " 0.8106927860087613,\n",
       " 0.8131847193121398,\n",
       " 0.8091160524764345,\n",
       " 0.810590147174833,\n",
       " 0.8082311419603222,\n",
       " 0.8087459813358888,\n",
       " 0.8123997733860646,\n",
       " 0.811169882707729,\n",
       " 0.8123173735188809,\n",
       " 0.810785983150871,\n",
       " 0.8086710086856809,\n",
       " 0.8113814742269905,\n",
       " 0.8094798175149532,\n",
       " 0.8109064115828561,\n",
       " 0.8144680184299059,\n",
       " 0.8179287456619596,\n",
       " 0.8111346389370148,\n",
       " 0.8147098061915495,\n",
       " 0.808942389437634,\n",
       " 0.8079495949658548,\n",
       " 0.8088342182032755,\n",
       " 0.8133510748477459,\n",
       " 0.8105363987556566,\n",
       " 0.8124411574876189,\n",
       " 0.8110171020926419,\n",
       " 0.8094921674260142,\n",
       " 0.8073545677451505,\n",
       " 0.8077815691472114,\n",
       " 0.8071537134303995,\n",
       " 0.8098428718291207,\n",
       " 0.811121509875093,\n",
       " 0.8158861658181773,\n",
       " 0.8127424717440298,\n",
       " 0.8106978174178723,\n",
       " 0.811628475988571,\n",
       " 0.8131312856204427,\n",
       " 0.8128664603276998,\n",
       " 0.8123739496956496,\n",
       " 0.8080975102802822,\n",
       " 0.8133611944041531,\n",
       " 0.8112376410542808,\n",
       " 0.8073482469929223,\n",
       " 0.812273797701115,\n",
       " 0.8096599935047318,\n",
       " 0.8090393640324869,\n",
       " 0.8090233998854521,\n",
       " 0.8115369920221744,\n",
       " 0.8076335653332896,\n",
       " 0.816117979205804,\n",
       " 0.8121403751112516,\n",
       " 0.8082688812042104,\n",
       " 0.8149037867782033,\n",
       " 0.8113398420384751,\n",
       " 0.8121099954914127,\n",
       " 0.8159623658459372,\n",
       " 0.8061102700374115,\n",
       " 0.8078885035303731,\n",
       " 0.8110138678029319,\n",
       " 0.8097747404358695,\n",
       " 0.8082955446363329,\n",
       " 0.8109330448516785,\n",
       " 0.8105209385081966,\n",
       " 0.8088408493602532,\n",
       " 0.8109368145598136,\n",
       " 0.8111853164664561,\n",
       " 0.8106110105807756,\n",
       " 0.8109848929407191,\n",
       " 0.8110133448447757,\n",
       " 0.8097794917255707,\n",
       " 0.8138178878258154,\n",
       " 0.8086397374972752,\n",
       " 0.8074229151874113,\n",
       " 0.8097726049140759,\n",
       " 0.8157700240944422,\n",
       " 0.8071990984054093,\n",
       " 0.813437022395168,\n",
       " 0.812875103271723,\n",
       " 0.8132606956786514,\n",
       " 0.8122452086358672,\n",
       " 0.809260032989068,\n",
       " 0.8085187542426138,\n",
       " 0.8095803051628798,\n",
       " 0.8106155406113938,\n",
       " 0.8077063312921902,\n",
       " 0.8134560632408164,\n",
       " 0.8112529188900449,\n",
       " 0.8086726476552211,\n",
       " 0.8100480852898162,\n",
       " 0.8125020033210213,\n",
       " 0.8086195654098173,\n",
       " 0.8085528197239849,\n",
       " 0.8081801065617014,\n",
       " 0.81078199074815,\n",
       " 0.808542341801321,\n",
       " 0.8100880684918587,\n",
       " 0.8107402319176452,\n",
       " 0.8122800263848352,\n",
       " 0.8036026382117958,\n",
       " 0.8116554332682729,\n",
       " 0.8097582041134015,\n",
       " 0.8105259713681169,\n",
       " 0.8102158294560652,\n",
       " 0.8089792082498554,\n",
       " 0.8123319283292888,\n",
       " 0.8095123317147724,\n",
       " 0.8102439583890237,\n",
       " 0.8127358435826836,\n",
       " 0.8077178748046691,\n",
       " 0.8128227630475066,\n",
       " 0.8066752269037327,\n",
       " 0.8076444785531148,\n",
       " 0.8143919450828533,\n",
       " 0.8099912917203617,\n",
       " 0.8136446554796285,\n",
       " 0.8096244899218626,\n",
       " 0.8105538349932842,\n",
       " 0.810610910240477,\n",
       " 0.8099930175285006,\n",
       " 0.809735200118186,\n",
       " 0.8117830295781168,\n",
       " 0.8104618984274037,\n",
       " 0.8105099565115378,\n",
       " 0.8070104592648225,\n",
       " 0.81156336669614,\n",
       " 0.8107763177695341,\n",
       " 0.8119120188096112,\n",
       " 0.8117304142294696,\n",
       " 0.8124248003686061,\n",
       " 0.8124573394778899,\n",
       " 0.8107719901003612,\n",
       " 0.8097559709458699,\n",
       " 0.810084914532143,\n",
       " 0.8127127283884059,\n",
       " 0.8140516339313681,\n",
       " 0.8126449714166645,\n",
       " 0.8071289896542642,\n",
       " 0.8133031692953862,\n",
       " 0.8106133724852613,\n",
       " 0.8183534175200486,\n",
       " 0.8113094534881135,\n",
       " 0.8144649241451829,\n",
       " 0.8074511350730256,\n",
       " 0.8108302713979018,\n",
       " 0.8072794176762262,\n",
       " 0.8078016059504922,\n",
       " 0.8081057127631506,\n",
       " 0.8094938718185447,\n",
       " 0.8108147811768157,\n",
       " 0.8130337916573895,\n",
       " 0.809742053264133,\n",
       " 0.8084524220428604,\n",
       " 0.8101949058323157,\n",
       " 0.8074861241964295,\n",
       " 0.8066585676378445,\n",
       " 0.8071281245274133,\n",
       " 0.8119833704393875,\n",
       " 0.8104526094035239,\n",
       " 0.811825654497741,\n",
       " 0.8134905789284452,\n",
       " 0.8111926806551275,\n",
       " 0.810980152805067,\n",
       " 0.8111062907675369,\n",
       " 0.8126154017612268,\n",
       " 0.8129748096268458,\n",
       " 0.8133905272869949,\n",
       " 0.8092609881705145,\n",
       " 0.8164127054955673,\n",
       " 0.8074591419333701,\n",
       " 0.811670692069138,\n",
       " 0.8135698291388251,\n",
       " 0.8060647953129051,\n",
       " 0.8090283730145408,\n",
       " 0.8112025355772623,\n",
       " 0.8129112329081216,\n",
       " 0.8096636318025969,\n",
       " 0.8076719916011095,\n",
       " 0.8183621463046739,\n",
       " 0.8087295171419973,\n",
       " 0.8098512153822147,\n",
       " 0.8124781259105356,\n",
       " 0.8130629513144032,\n",
       " 0.8075599963678503,\n",
       " 0.8160936235868121,\n",
       " 0.8088190017552727,\n",
       " 0.8096913705265809,\n",
       " 0.8144420798753788,\n",
       " 0.8088900541738903,\n",
       " 0.8140385537469315,\n",
       " 0.8095747413970343,\n",
       " 0.8112894452938841,\n",
       " 0.8087364684026633,\n",
       " 0.8065849535306345,\n",
       " 0.8099252495066966,\n",
       " 0.8100454855689987,\n",
       " 0.8091458135845764,\n",
       " 0.8087776470381384,\n",
       " 0.817513471237101,\n",
       " 0.8086527089276778,\n",
       " 0.8091746804240989,\n",
       " 0.809509947736873,\n",
       " 0.8078464003782941,\n",
       " 0.8160755777355374,\n",
       " 0.8151879597211495,\n",
       " 0.8140589293108594,\n",
       " 0.8155206690822124,\n",
       " 0.8109404347436064,\n",
       " 0.8118068290120171,\n",
       " 0.8061081196313988,\n",
       " 0.8092502289971747,\n",
       " 0.8113671872437783,\n",
       " 0.8101733146733909,\n",
       " 0.8114080952616947,\n",
       " 0.8140588565380421,\n",
       " 0.8070480523819898,\n",
       " 0.8089821750181012,\n",
       " 0.8114867743516112,\n",
       " 0.814081575717933,\n",
       " 0.8099839350906509,\n",
       " 0.8111670161126796,\n",
       " 0.8098396547455615,\n",
       " 0.8128675660588757,\n",
       " 0.8161680937746401,\n",
       " 0.8087407878386507,\n",
       " 0.8079685087811755,\n",
       " 0.8116470856544025,\n",
       " 0.8121227200551424,\n",
       " 0.8086588950058418,\n",
       " 0.8058622631719957,\n",
       " 0.8102764253961339,\n",
       " 0.8117198922108665,\n",
       " 0.8048065533153921,\n",
       " 0.8107956886172211,\n",
       " 0.8084408500533032,\n",
       " 0.8087962782497267,\n",
       " 0.8106059379666994,\n",
       " 0.8100721720295874,\n",
       " 0.811343549481022,\n",
       " 0.8113952445379625,\n",
       " 0.807765469710532,\n",
       " 0.8074162413565817,\n",
       " 0.8107165942756392,\n",
       " 0.8117843167204343,\n",
       " 0.8133300563035413,\n",
       " 0.8092781980136565,\n",
       " 0.8102547812316563,\n",
       " 0.8088066291913925,\n",
       " 0.8107354982951018,\n",
       " 0.8108337406476933,\n",
       " 0.8077794577476124,\n",
       " 0.8083453268152504,\n",
       " 0.8143069658860588,\n",
       " 0.8088519962812415,\n",
       " 0.8107395152313641,\n",
       " 0.8093564993513639,\n",
       " 0.8073333359263875,\n",
       " 0.8116732244677558,\n",
       " 0.8138540300369836,\n",
       " 0.8100583479932671,\n",
       " 0.8150070568673531,\n",
       " 0.8079445427864431,\n",
       " 0.8155433954676524,\n",
       " 0.8076849939443735,\n",
       " 0.8094852372533574,\n",
       " 0.8177890352415672,\n",
       " 0.8072089417943342,\n",
       " 0.8141213851556175,\n",
       " 0.8103483591346158,\n",
       " 0.8126224393948022,\n",
       " 0.809155028827193,\n",
       " 0.8085207770247159,\n",
       " 0.8112998518844002,\n",
       " 0.8123930160201356,\n",
       " 0.8094283766930673,\n",
       " 0.8120151726728617,\n",
       " 0.8113603249725708,\n",
       " 0.807985417450337,\n",
       " 0.8111794684018983,\n",
       " 0.8075354539334864,\n",
       " 0.8074987492134178,\n",
       " 0.8107197834031582,\n",
       " 0.8105698123736071,\n",
       " 0.8057444969949916,\n",
       " 0.8117871597878925,\n",
       " 0.807862741245885,\n",
       " 0.807269516700931,\n",
       " 0.8086924718158021,\n",
       " 0.8079008185646209,\n",
       " 0.8122385045464376,\n",
       " 0.8095478226373876,\n",
       " 0.8096334314534328,\n",
       " 0.8082254472226262,\n",
       " 0.8124292192736368,\n",
       " 0.807591801655969,\n",
       " 0.8086527401336806,\n",
       " 0.8081326342334022,\n",
       " 0.8095635580176379,\n",
       " 0.8131030929259535,\n",
       " 0.8070758343277215,\n",
       " 0.8094340778673434,\n",
       " 0.812472961562964,\n",
       " 0.8120199937634874,\n",
       " 0.8110621353598194,\n",
       " 0.8123926255441855,\n",
       " 0.8108247964871267,\n",
       " 0.8094352096413083,\n",
       " 0.8109306139388411,\n",
       " 0.8110169116723723,\n",
       " 0.8079589562508384,\n",
       " 0.8107283270866038,\n",
       " 0.8125915470710465,\n",
       " 0.810849192770057,\n",
       " 0.8126879670805449,\n",
       " 0.8080242241775614,\n",
       " 0.8094089966453885,\n",
       " 0.8101754950065403,\n",
       " 0.8127177202490965,\n",
       " 0.8127657157975299,\n",
       " 0.8086435755291389,\n",
       " 0.8106640664356193,\n",
       " 0.8138204428312887,\n",
       " 0.811395421186875,\n",
       " 0.812732667325548,\n",
       " 0.8124009651237085,\n",
       " 0.8127384900279968,\n",
       " 0.8042324300260341,\n",
       " 0.8075127788743168,\n",
       " 0.8136573624695506,\n",
       " 0.8117716684512352,\n",
       " 0.8102526405394211,\n",
       " 0.8187174513658578,\n",
       " 0.8156433960918626,\n",
       " 0.8083112516737042,\n",
       " 0.8091708582020253,\n",
       " 0.8102437296996504,\n",
       " 0.8113751829260217,\n",
       " 0.8093069929584965,\n",
       " 0.8062434443649678,\n",
       " 0.8119025662687072,\n",
       " 0.8100331783908548,\n",
       " 0.8092988870664677,\n",
       " 0.812596884911863,\n",
       " 0.8117773512753473,\n",
       " 0.816147842349785,\n",
       " 0.8124177601876762,\n",
       " 0.809531466873339,\n",
       " 0.8075053669988044,\n",
       " 0.8146517287872175,\n",
       " 0.8118164053164477,\n",
       " 0.809625740108233,\n",
       " 0.8101618092939525,\n",
       " 0.8112585247643889,\n",
       " 0.8089905339300059,\n",
       " 0.8110939394794604,\n",
       " 0.8141092460903084,\n",
       " 0.811508404711466,\n",
       " 0.8159547046330938,\n",
       " 0.813356866901353,\n",
       " 0.8133626039924247,\n",
       " 0.8103215483132865,\n",
       " 0.8115032348112787,\n",
       " 0.8102371005857628,\n",
       " 0.8079917871552069,\n",
       " 0.8112215751449373,\n",
       " 0.812402661198353,\n",
       " 0.8122030808986205,\n",
       " 0.8086677011581397,\n",
       " 0.8100845555779668,\n",
       " 0.812849156387054,\n",
       " 0.8111424367791877,\n",
       " 0.8117318463085899,\n",
       " 0.8099650575543957,\n",
       " 0.8077458756220828,\n",
       " 0.8117906798377723,\n",
       " 0.811795256032973,\n",
       " 0.8122985958697005,\n",
       " 0.8088199884947833,\n",
       " 0.8104453235032479,\n",
       " 0.810886751994453,\n",
       " 0.8083368265832366,\n",
       " 0.8092406614127879,\n",
       " 0.8111372332172179,\n",
       " 0.8103613356012227,\n",
       " 0.8043102894991991,\n",
       " 0.8107258032682985,\n",
       " 0.811501655807849,\n",
       " 0.8153955285507819,\n",
       " 0.8111606266617909,\n",
       " 0.8118429223500624,\n",
       " 0.8061027457839933,\n",
       " 0.8107554148512353,\n",
       " 0.8108583507464262,\n",
       " 0.8094967185459773,\n",
       " 0.807069629591954,\n",
       " 0.8065782464020068,\n",
       " 0.8124509417094415,\n",
       " 0.8113631478577531,\n",
       " 0.8080379765984645,\n",
       " 0.8155490662681101,\n",
       " 0.8136029879157319,\n",
       " 0.8071977455434036,\n",
       " 0.8116983610748021,\n",
       " 0.8094914081962,\n",
       " 0.8125830378787764,\n",
       " 0.8080609941025609,\n",
       " 0.8105961082636295,\n",
       " 0.8137963182689003,\n",
       " 0.8103980966929146,\n",
       " 0.8078696138262214,\n",
       " 0.8129199493696571,\n",
       " 0.8089688621216374,\n",
       " 0.8132153451982801,\n",
       " 0.8130416262551211,\n",
       " 0.8105927403474631,\n",
       " 0.8092988735215222,\n",
       " 0.8065850258826932,\n",
       " 0.8081197212114989,\n",
       " 0.8165093154289573,\n",
       " 0.8116446703510805,\n",
       " 0.8130454003265962,\n",
       " 0.8137642848862665,\n",
       " 0.8103540783049583,\n",
       " 0.8089347507187081,\n",
       " 0.8076573562142726,\n",
       " 0.8118157441471716,\n",
       " 0.8146583318144955,\n",
       " 0.8141390868278934,\n",
       " 0.8113520139738539,\n",
       " 0.8091958684571174,\n",
       " 0.8090934516466344,\n",
       " 0.8113032860460758,\n",
       " 0.8126209816320092,\n",
       " 0.8070889208966963,\n",
       " 0.8115497594750881,\n",
       " 0.8122513565062986,\n",
       " 0.8139256908243436,\n",
       " 0.8127804324364052,\n",
       " 0.8081791951762785,\n",
       " 0.8113134107375982,\n",
       " 0.8107219953656722,\n",
       " 0.8082294056153257,\n",
       " 0.8080885955440691,\n",
       " 0.8106967914681994,\n",
       " 0.8113760066873142,\n",
       " 0.813389844603946,\n",
       " 0.8115816369970732,\n",
       " 0.8106350231443972,\n",
       " 0.812414791522697,\n",
       " 0.8087176226195527,\n",
       " 0.8100831550184939,\n",
       " 0.8116877847498803,\n",
       " 0.8087142837969025,\n",
       " 0.8107597298023753,\n",
       " 0.8084507241695713,\n",
       " 0.8144813932479413,\n",
       " 0.8060665311357262,\n",
       " 0.8105890862013996,\n",
       " 0.8117689610893308,\n",
       " 0.8113512433465822,\n",
       " 0.8089931447414485,\n",
       " 0.8094210694726339,\n",
       " 0.8178874016938987,\n",
       " 0.8093950027962047,\n",
       " 0.8126990664350733,\n",
       " 0.811880850139738,\n",
       " 0.8115594575809165,\n",
       " 0.8063284882891584,\n",
       " 0.8088666598228497,\n",
       " 0.8146557912260749,\n",
       " 0.8135678004757195,\n",
       " 0.8120002441073949,\n",
       " 0.8112556578817856,\n",
       " 0.8096282542304799,\n",
       " 0.8133172016872556,\n",
       " 0.8146259899219427,\n",
       " 0.8086915055303813,\n",
       " 0.811274547629588,\n",
       " 0.8113122701196891,\n",
       " 0.8112281332612151,\n",
       " 0.8098651877293542,\n",
       " 0.81103549345269,\n",
       " 0.8064659517487969,\n",
       " 0.8131012292847619,\n",
       " 0.8116340066265717,\n",
       " 0.80944629797272,\n",
       " 0.8126415930956238,\n",
       " 0.8095598668223569,\n",
       " 0.8067978200191295,\n",
       " 0.8158090000755659,\n",
       " 0.8097298313048455,\n",
       " 0.8120229721345076,\n",
       " 0.811085901437667,\n",
       " 0.8130262269024918,\n",
       " 0.8114585126712848,\n",
       " 0.806583963854345,\n",
       " 0.812256148086056,\n",
       " 0.8068836087477717,\n",
       " 0.81484766906398,\n",
       " 0.8079085387992462,\n",
       " 0.8088427873142624,\n",
       " 0.8064398835865298,\n",
       " 0.8076705165320269,\n",
       " 0.812921841161996,\n",
       " 0.8086995124258752,\n",
       " 0.8137716512061848,\n",
       " 0.8096450042510649,\n",
       " 0.8125656846202064,\n",
       " 0.8098529746083858,\n",
       " 0.8119486215447864,\n",
       " 0.8080570851135707,\n",
       " 0.8153900082535386,\n",
       " 0.81276142498425,\n",
       " 0.8114271417718331,\n",
       " 0.8083857352126234,\n",
       " 0.8140444551028752,\n",
       " 0.8071554889293626,\n",
       " 0.8062702988982016,\n",
       " 0.8103016068966614,\n",
       " 0.8106147134739432,\n",
       " 0.8109846769491976,\n",
       " 0.8137606462615983,\n",
       " 0.8069627847939648,\n",
       " 0.8115358163687827,\n",
       " 0.8130173360254307,\n",
       " 0.8058780309815715,\n",
       " 0.8148189051448964,\n",
       " 0.8086343393117129,\n",
       " 0.808531016700006,\n",
       " 0.8122513186593439,\n",
       " 0.8114278851302295,\n",
       " 0.8116184426418512,\n",
       " 0.8065880421850145,\n",
       " 0.8128298871101282,\n",
       " 0.8139295600313282,\n",
       " 0.8100265148297842,\n",
       " 0.8134681228803919,\n",
       " 0.8090111812195216,\n",
       " 0.8122733087793726,\n",
       " 0.8112544378463976,\n",
       " 0.8131352259652221,\n",
       " 0.8115256173235483,\n",
       " 0.8085224170315127,\n",
       " 0.8100082719231748,\n",
       " 0.811190318202651,\n",
       " 0.8129971853255054,\n",
       " 0.8120508263165191,\n",
       " 0.8071592564226974,\n",
       " 0.8088965429009496,\n",
       " 0.8075794202135201,\n",
       " 0.8111785821982946,\n",
       " 0.8104450303422875,\n",
       " 0.8101095310800313,\n",
       " 0.8169044086059886,\n",
       " 0.8126330749476023,\n",
       " 0.8100316358347217,\n",
       " 0.8097356504904307,\n",
       " 0.8090968815376892,\n",
       " 0.8151279626978704,\n",
       " 0.8063438012604313,\n",
       " 0.8095915064787488,\n",
       " 0.8109160268699814,\n",
       " 0.811404451240561,\n",
       " 0.8083964140497721,\n",
       " 0.8109658029352333,\n",
       " 0.8100994496966317,\n",
       " 0.8086893926419296,\n",
       " 0.8120967461055398,\n",
       " 0.8068674733163694,\n",
       " 0.8118369233451033,\n",
       " 0.8112259337726472,\n",
       " 0.8082103963223238,\n",
       " 0.8130072895564294,\n",
       " 0.8109844462000352,\n",
       " 0.809063498586882,\n",
       " 0.8125599393507033,\n",
       " 0.8094890518587843,\n",
       " 0.8131390514170227,\n",
       " 0.8096950006736625,\n",
       " 0.8068955318078809,\n",
       " 0.8138492081817564,\n",
       " 0.8063940558839678,\n",
       " 0.8112422141158055,\n",
       " 0.8122247371070375,\n",
       " 0.8077394865909062,\n",
       " 0.8081264755237691,\n",
       " 0.811612740161311,\n",
       " 0.8113931609198782,\n",
       " 0.8091137300331923,\n",
       " 0.8107638372961581,\n",
       " 0.8116253287320039,\n",
       " 0.8099997856276782,\n",
       " 0.8124096372722933,\n",
       " 0.8122307469447796,\n",
       " 0.810945216027213,\n",
       " 0.8086934752364442,\n",
       " 0.8150192069824425,\n",
       " 0.8110052867849554,\n",
       " 0.805248496416566,\n",
       " 0.8089458629952624,\n",
       " 0.8070290384899611,\n",
       " 0.8120861300547031,\n",
       " 0.8119265222388828,\n",
       " 0.8050294402890822,\n",
       " 0.8080211180375941,\n",
       " 0.8115491741413688,\n",
       " 0.8095719636563818,\n",
       " 0.809637709749125,\n",
       " 0.8092686160849476,\n",
       " 0.8073408796167076,\n",
       " 0.8116535115251859,\n",
       " 0.8114401498732847,\n",
       " 0.809598968471044,\n",
       " 0.8067585341561594,\n",
       " 0.8096875751781828,\n",
       " 0.8135598448507179,\n",
       " 0.8132334570156545,\n",
       " 0.8121486430236389,\n",
       " 0.8135994042973916,\n",
       " 0.8055543735466839,\n",
       " 0.8103465798478637,\n",
       " 0.8143203256488213,\n",
       " 0.8124860854750864,\n",
       " 0.8114098746820431,\n",
       " 0.809455176347315,\n",
       " 0.8104229417833498,\n",
       " 0.8112562536079599,\n",
       " 0.8091501459412588,\n",
       " 0.8113762492357096,\n",
       " 0.8083181367048194,\n",
       " 0.8116567798968118,\n",
       " 0.8097669635007938,\n",
       " 0.8133279599553406,\n",
       " 0.8081244706252004,\n",
       " 0.8130827014613463,\n",
       " 0.8097559298009712,\n",
       " 0.8086459509337894,\n",
       " 0.8104362273251902,\n",
       " 0.8081658006736282,\n",
       " 0.809974067309241,\n",
       " 0.813598130778147,\n",
       " 0.8098577037745343,\n",
       " 0.8087767589859763,\n",
       " 0.8103850275906695,\n",
       " 0.812643560046971,\n",
       " 0.8067054972737874,\n",
       " 0.809734727146742,\n",
       " 0.8083121875141273,\n",
       " 0.8108792065147051,\n",
       " 0.8090596863306458,\n",
       " 0.8131616083938343,\n",
       " 0.8081878327912181,\n",
       " 0.8098859790010366,\n",
       " 0.8075518306411641,\n",
       " 0.8075941560031377,\n",
       " 0.8080813022894386,\n",
       " 0.81441828935423,\n",
       " 0.8083018321717408,\n",
       " 0.8086227378683505,\n",
       " 0.811788355529567,\n",
       " 0.8094821347142873,\n",
       " 0.8074462419454518,\n",
       " 0.8096716178637503,\n",
       " 0.8130378270992682,\n",
       " 0.8082784361162826,\n",
       " 0.8097044260084688,\n",
       " 0.8113894181005964,\n",
       " 0.804821518460825,\n",
       " 0.8071228005955393,\n",
       " 0.8113528280841924,\n",
       " 0.807328605307004,\n",
       " 0.8133695276419813,\n",
       " 0.8109793505724764,\n",
       " 0.8078229670876083,\n",
       " 0.8087381664365306,\n",
       " 0.8071136365230314,\n",
       " 0.8122232900990509,\n",
       " 0.8134365817924756,\n",
       " 0.8114930094319485,\n",
       " 0.8093618776378892,\n",
       " 0.8091080078924464,\n",
       " 0.8095789620541333,\n",
       " 0.8120206203021602,\n",
       " 0.8100306875386384,\n",
       " 0.8123445804259269,\n",
       " 0.8093183026565778,\n",
       " 0.8089688890216598,\n",
       " 0.8084994887533358,\n",
       " 0.8098373978027176,\n",
       " 0.8098702105052842,\n",
       " 0.8060640520384988,\n",
       " 0.8075673506633932,\n",
       " 0.8126963997657733,\n",
       " 0.8155335964282712,\n",
       " 0.812423772281982,\n",
       " 0.8108518831251961,\n",
       " 0.8125293791698807,\n",
       " 0.8103183546936574,\n",
       " 0.8078857115752303,\n",
       " 0.8055960600602333,\n",
       " 0.8154282150837938,\n",
       " 0.8113391606905246,\n",
       " 0.8096930545856263,\n",
       " 0.8159796442580305,\n",
       " 0.811943737350826,\n",
       " 0.8045712578560102,\n",
       " 0.8109832358748967,\n",
       " 0.8144572470627368,\n",
       " 0.8104035128250581,\n",
       " 0.8130956958618794,\n",
       " 0.8086323809025033,\n",
       " 0.8114682485314605,\n",
       " 0.8146787119122413,\n",
       " 0.8099500905782379,\n",
       " 0.8086820195353083,\n",
       " 0.8130228269399845,\n",
       " 0.8116938817860865,\n",
       " 0.8132069726549472,\n",
       " 0.8074457540858928,\n",
       " 0.8128849619094974,\n",
       " 0.8118395059496245,\n",
       " 0.8089481514552497,\n",
       " 0.812194737131097,\n",
       " 0.8094743594370493,\n",
       " 0.8090578820821692,\n",
       " 0.8167132618686804,\n",
       " 0.8114543127424688,\n",
       " 0.8158623659550185,\n",
       " 0.812305931441159,\n",
       " 0.8106253841052076,\n",
       " 0.8153756898570667,\n",
       " 0.8150615694588776,\n",
       " 0.8079806937645321,\n",
       " 0.8120278128467714,\n",
       " 0.8129646515893366,\n",
       " 0.8121973358522865,\n",
       " 0.8143338313214855,\n",
       " 0.8100367429816618,\n",
       " 0.8084812597374327,\n",
       " 0.8113955852984048,\n",
       " 0.8132580689422562,\n",
       " 0.8087628643531228,\n",
       " 0.810216101745388,\n",
       " 0.8086981870262863,\n",
       " 0.8060741199016591,\n",
       " 0.8131832414580573,\n",
       " 0.8095420191986337,\n",
       " 0.8114340366946826,\n",
       " 0.8143748731752414,\n",
       " 0.8134809800607863,\n",
       " 0.8108993784725573,\n",
       " 0.809407237614682,\n",
       " 0.8128826911107423,\n",
       " 0.8146949803302691,\n",
       " 0.8083495806697096,\n",
       " 0.8127157725439157,\n",
       " 0.811680002830465,\n",
       " 0.8068418783857789,\n",
       " 0.8056755684001864,\n",
       " 0.8095031702918578,\n",
       " 0.8129130025823281,\n",
       " 0.8128578451822333,\n",
       " 0.8084773696566949,\n",
       " 0.8129167152129693,\n",
       " 0.8086463073585991,\n",
       " 0.80590933789416,\n",
       " 0.8111454833336335,\n",
       " 0.81116734726986,\n",
       " 0.8153516772810955,\n",
       " 0.8117253093969684,\n",
       " 0.8131924084629775,\n",
       " 0.8121591039340157,\n",
       " 0.8141946783564968,\n",
       " 0.8105029187107239,\n",
       " 0.8143728485484693,\n",
       " 0.806001374074866,\n",
       " 0.812246563661857,\n",
       " 0.8134720136860966,\n",
       " 0.8121446615212307,\n",
       " 0.8136784146898522,\n",
       " 0.8134351869080124,\n",
       " 0.8092340817110992,\n",
       " 0.8107504763296173,\n",
       " 0.8059722359699375,\n",
       " 0.8096272626870026,\n",
       " 0.8064821502219822,\n",
       " 0.8144114454532639,\n",
       " 0.8115508318877427,\n",
       " 0.811015928256953,\n",
       " 0.8094588130682587,\n",
       " 0.8099451031849513,\n",
       " 0.8148033825583771,\n",
       " 0.8051718397054658,\n",
       " 0.8133915579446576,\n",
       " 0.8165728646464778,\n",
       " 0.8120212637913602,\n",
       " 0.8111992937607825,\n",
       " 0.808221005786856,\n",
       " 0.8117219628169517,\n",
       " 0.8136165917777896,\n",
       " 0.8112467799035193,\n",
       " 0.8102094562749584,\n",
       " 0.8061690663416702,\n",
       " 0.8102134691789605,\n",
       " 0.8099449880033168,\n",
       " 0.8102745459933157,\n",
       " 0.8118439703857682,\n",
       " 0.8139667762063566,\n",
       " 0.8097613529347284,\n",
       " 0.8106674911051183,\n",
       " 0.8114012037713805,\n",
       " 0.8093739108887721,\n",
       " 0.8116223163114635,\n",
       " 0.8092848045473896,\n",
       " 0.8114793511058837,\n",
       " 0.8106375960280141,\n",
       " 0.8141502259580178,\n",
       " 0.8076697360388178,\n",
       " 0.8132976265112077,\n",
       " 0.8128142175236601,\n",
       " 0.8092889523310833,\n",
       " 0.808495048150918,\n",
       " 0.8110874501619012,\n",
       " 0.8092020909352651,\n",
       " 0.8122137091990377,\n",
       " 0.8168643548504431,\n",
       " 0.8126979093126935,\n",
       " 0.8115235539725635,\n",
       " 0.8095370114979579,\n",
       " 0.807004351270173,\n",
       " 0.8074556222131725,\n",
       " 0.8081800389022391,\n",
       " 0.81033394955995,\n",
       " 0.8155889687089686,\n",
       " 0.81246742766441,\n",
       " 0.8082074844425672,\n",
       " 0.8105837726403947,\n",
       " 0.8100324994627672,\n",
       " 0.8090865808708418,\n",
       " 0.8098969371932673,\n",
       " 0.81291074031883,\n",
       " 0.8100714998699414,\n",
       " 0.8134151717535779,\n",
       " 0.8082182502917339,\n",
       " 0.8115725553136108,\n",
       " 0.8106539666831236,\n",
       " 0.8071432144140619,\n",
       " 0.8086578344729006,\n",
       " 0.81364680694832,\n",
       " 0.8058011445775514,\n",
       " 0.8105851737825424,\n",
       " 0.8092783003710112,\n",
       " 0.8103447891041476,\n",
       " 0.8089422343174829,\n",
       " 0.8157289970574627,\n",
       " 0.8120309560071207,\n",
       " 0.8132813640829709,\n",
       " 0.8126991931806173,\n",
       " 0.8139596268196508,\n",
       " 0.812698077710553,\n",
       " 0.810855936274035,\n",
       " 0.807777660283209,\n",
       " 0.8122616903982343,\n",
       " 0.8083170165070187,\n",
       " 0.8099189185035323,\n",
       " 0.8122416405098647,\n",
       " 0.80937478691628,\n",
       " 0.8068498113518915,\n",
       " 0.8109659313016184,\n",
       " 0.8120511563049613,\n",
       " 0.8102545995081913,\n",
       " 0.8110906347842755,\n",
       " 0.8101321675080966,\n",
       " 0.8136247358875119,\n",
       " 0.8131156758387333,\n",
       " 0.8116007588726357,\n",
       " 0.8105122116078113,\n",
       " 0.8107940740711159,\n",
       " 0.8072746026592699,\n",
       " 0.8083349733973398,\n",
       " 0.8066043922958718,\n",
       " 0.8119160879803977,\n",
       " 0.8104758509321455,\n",
       " 0.8092408475240357,\n",
       " 0.814243245016113,\n",
       " 0.8175150436855292,\n",
       " 0.8088159994069081,\n",
       " 0.8079203025877626,\n",
       " 0.812511558306558,\n",
       " 0.8123260818563017,\n",
       " 0.8114120614905247,\n",
       " 0.812587979985609,\n",
       " 0.8119071826557215,\n",
       " 0.8107955495022232,\n",
       " 0.8164282931135795,\n",
       " 0.8089510095410091,\n",
       " 0.8103211523215316,\n",
       " 0.8081341767168237,\n",
       " 0.8125203844631029,\n",
       " 0.8125826430852993,\n",
       " 0.8140197677521355,\n",
       " 0.8109522577192201,\n",
       " 0.8105846212918761,\n",
       " 0.8114861563982156,\n",
       " 0.8129967730112813,\n",
       " 0.8116755177288536,\n",
       " 0.8138343474037243,\n",
       " 0.8103839798565639,\n",
       " 0.8086794033192989,\n",
       " 0.8117166697590972,\n",
       " 0.808492713341879,\n",
       " 0.8108434466911217,\n",
       " 0.8124970097336783,\n",
       " 0.8091579556069923,\n",
       " 0.808319695550373,\n",
       " 0.8106085344076138,\n",
       " 0.8132335860936185,\n",
       " 0.8151791770925465,\n",
       " 0.8107305244286794,\n",
       " 0.8095690546099606,\n",
       " 0.8132988173758621,\n",
       " 0.8099718508391192,\n",
       " 0.8127960630933426,\n",
       " 0.8129380465178645,\n",
       " 0.8079359509800353,\n",
       " 0.8088655995351778,\n",
       " 0.8090139668523565,\n",
       " 0.8101846748687263,\n",
       " 0.8131277930485505,\n",
       " 0.8105086751457858,\n",
       " 0.8154927223591247,\n",
       " 0.8131238387900324,\n",
       " 0.8126281882199423,\n",
       " 0.8121906461868447,\n",
       " 0.8065487609348276,\n",
       " 0.8085775520478496,\n",
       " 0.8064776857497055,\n",
       " 0.8089244208754937,\n",
       " 0.8147962355834496,\n",
       " 0.8127894840598316,\n",
       " 0.8095882582282874,\n",
       " 0.8105639262584691,\n",
       " 0.8123217024568309,\n",
       " 0.8113484814977057,\n",
       " 0.8133213228908721,\n",
       " 0.8088613171780582,\n",
       " 0.8145630955422913,\n",
       " 0.8105937194804236,\n",
       " 0.810576453058093,\n",
       " 0.8082114456485417,\n",
       " 0.8107513143075902,\n",
       " 0.8120050452828848,\n",
       " 0.812594993263683,\n",
       " 0.8072600560845122,\n",
       " 0.8146378992547917,\n",
       " 0.8112189749539725,\n",
       " 0.810760976159739,\n",
       " 0.8130816778858437,\n",
       " 0.8085977885783161,\n",
       " 0.8107676975834549,\n",
       " 0.8105918178030862,\n",
       " 0.8046188747759417,\n",
       " 0.812581159791293,\n",
       " 0.8103645250662431,\n",
       " 0.8076803029182292,\n",
       " 0.8132094058282544,\n",
       " 0.8153326479888988,\n",
       " 0.8135387903916694,\n",
       " 0.8143103643125265,\n",
       " 0.8117120749660286,\n",
       " 0.8085884024611515,\n",
       " 0.8054958671825753,\n",
       " 0.8171240640890153,\n",
       " 0.8147421226419427,\n",
       " 0.809586824003731,\n",
       " 0.8120271223115498,\n",
       " 0.8116718501403296,\n",
       " 0.8090180837029656,\n",
       " 0.8104077674310874,\n",
       " 0.8107156081483363,\n",
       " 0.8102305179882983,\n",
       " 0.8120284325070675,\n",
       " 0.8121655481634265,\n",
       " 0.8078160642843032,\n",
       " 0.8127043856878178,\n",
       " 0.8096702232021113,\n",
       " 0.8097452220125834,\n",
       " 0.8074444578295599,\n",
       " 0.8115274799698713,\n",
       " 0.8071502038921768]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\"\"\" Apply bootstrapping to simulate the distribution of f1_weighted\"\"\"\n",
    "\n",
    "n_resamples = 1000\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(n_resamples):\n",
    "    test, actual = resample(x_test, y_test, stratify=y_test, replace=True)\n",
    "    pred = svc.predict(test)\n",
    "    f1_scores.append(f1_score(actual, pred, average='weighted'))\n",
    "f1_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f08a06b1b70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(f1_scores, kde=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean for f1_weighted:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104893063881606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**95-confidence interval for f1_weighted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95-confidence interval for f1_weighted is [0.8057792039111553,0.8151792037648334]\n"
     ]
    }
   ],
   "source": [
    "left_bound = np.quantile(f1_scores, 0.025)\n",
    "right_bound = np.quantile(f1_scores, 0.975)\n",
    "print( f\"95-confidence interval for f1_weighted is [{left_bound},{right_bound}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "MODEL_PATH = os.path.join(\".\", \"svc.sav\")\n",
    "\n",
    "with open(MODEL_PATH, \"wb\") as file:\n",
    "    pickle.dump(svc, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_jpt_notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
